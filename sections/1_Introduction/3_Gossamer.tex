\section{\name{}}

Multi-threaded applications perform much better than single threaded applications but are also more complex to 
design. The same is true when scaling applications from a single machine to a distributed 
setting. Here, lack of shared memory means that not all of the compute units (threads/processes) can access all 
of the shared objects, which also complicates the synchronization mechanisms. Distributed applications, historically, 
rely on message passing to share data. Remote Procedural Calls (RPCs) is one such framework where threads can send 
requests to where data is located and receive responses upon completion \cite{Birrell:1984:IRP:2080.357392,Srinivasan:1995:RRP:RFC1831,Bershad:1989:LRP:74850.74861,6702617,Adamson2016,Talpey2010,4228186,brabson2011method,shyam2015managing,merrick2015xml,Soumagne2013MercuryER}.
This is very similar to how delegation works.

\name{} extends \trust{} to build a rack-wide programming model. \name{} aims to provide a high performance and 
easy to program in, framework that can take advantage of the increased resources available in a rack. Using the 
API provided by \name{} programmers can code their applications like a normal delegation application with very 
few changes and the applications have the illusion of running on a single machine. Most of the distribution of 
work is handled behind the scenes, but programmers have the option to customize where the worker threads should 
run and where data should be held in the rack if they so choose. Table~\ref{tab:trust_vs_gsm} shows a minimal \trust{} 
example and how the same program looks like when using \name{}.
\input{tables/trust_vs_gsm}
% \input{tables/noref}

A key challenge that limits performance in distributed systems is the additional latency introduced by network 
communication. \name{} mitigates this by combining RDMA with as fibers. RDMA offers sub-microsecond one-way 
latency, significantly faster than accessing persistent storage on a single machine, though still slower than 
local memory and considerably slower than CPU cache accesses. Fibers are light weight user threads that run on 
top of system threads and help bridge this latency gap by allowing applications to issue and manage a large 
number of concurrent, outstanding requests. This is further amplified by batching the requests generated by all 
the fibers on a single system thread. While RDMA reduces latency, it does not scale efficiently as the number of 
connections per machine grows. To address this, \name{} maintains only a single RDMA connection per hardware 
thread for each remote machine.